{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and preprocessing and miscellaneous functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use mnist_train.csv as our training data and mnist_test.csv as our validation set\n",
    "http://pjreddie.com/projects/mnist-in-csv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('mnist_train.csv',header=None)\n",
    "test_set = pd.read_csv('mnist_test.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9   ...   775  776  777  778  \\\n",
       "0    7    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "1    2    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "2    1    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "3    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "4    4    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "\n",
       "   779  780  781  782  783  784  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get labels in own array\n",
    "train_lb=np.array(train_set[0])\n",
    "test_lb=np.array(test_set[0])\n",
    "\n",
    "#one hot encode the labels\n",
    "train_lb=(np.arange(10) == train_lb[:,None]).astype(np.float32)\n",
    "test_lb=(np.arange(10) == test_lb[:,None]).astype(np.float32)\n",
    "\n",
    "#drop the labels column from training dataframe\n",
    "trainX=train_set.drop(0,axis=1)\n",
    "testX=test_set.drop(0,axis=1)\n",
    "\n",
    "#put in correct float32 array format\n",
    "trainX=np.array(trainX).astype(np.float32)\n",
    "testX=np.array(testX).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reformat the data so it's not flat\n",
    "trainX=trainX.reshape(len(trainX),28,28,1)\n",
    "testX = testX.reshape(len(testX),28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get a validation set and remove it from the train set\n",
    "trainX,valX,train_lb,val_lb=trainX[0:(len(trainX)-500),:,:,:],trainX[(len(trainX)-500):len(trainX),:,:,:],\\\n",
    "                            train_lb[0:(len(trainX)-500),:],train_lb[(len(trainX)-500):len(trainX),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f97fbde6990>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFfCAYAAACfj30KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCBNCSItQhAkhpEX+f5mfadssU0IbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f97fb8df410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#make sure the images are alright\n",
    "plt.imshow(trainX.reshape(len(trainX),28,28)[0],cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#need to batch the test data because running low on memory\n",
    "class test_batchs:\n",
    "    def __init__(self,data):\n",
    "        self.data = data\n",
    "        self.batch_index = 0\n",
    "    def nextBatch(self,batch_size):\n",
    "        if (batch_size+self.batch_index) > self.data.shape[0]:\n",
    "            print \"batch sized is messed up\"\n",
    "        batch = self.data[self.batch_index:(self.batch_index+batch_size),:,:,:]\n",
    "        self.batch_index= self.batch_index+batch_size\n",
    "        return batch\n",
    "\n",
    "#set the test batchsize\n",
    "test_batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#returns accuracy of model\n",
    "def accuracy(target,predictions):\n",
    "    return(100.0*np.sum(np.argmax(target,1) == np.argmax(predictions,1))/target.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#use os to get our current working directory so we can save variable\n",
    "file_path = os.getcwd()+'/model.ckpt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Inception modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-6a15e6f91944>:147 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "map1 = 32\n",
    "map2 = 64\n",
    "num_fc1 = 700 #1028\n",
    "num_fc2 = 10\n",
    "reduce1x1 = 16\n",
    "dropout=0.5\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    #train data and labels\n",
    "    X = tf.placeholder(tf.float32,shape=(batch_size,28,28,1))\n",
    "    y_ = tf.placeholder(tf.float32,shape=(batch_size,10))\n",
    "    \n",
    "    #validation data\n",
    "    tf_valX = tf.placeholder(tf.float32,shape=(len(valX),28,28,1))\n",
    "    \n",
    "    #test data\n",
    "    tf_testX=tf.placeholder(tf.float32,shape=(test_batch_size,28,28,1))\n",
    "    \n",
    "    def createWeight(size,Name):\n",
    "        return tf.Variable(tf.truncated_normal(size, stddev=0.1),\n",
    "                          name=Name)\n",
    "    \n",
    "    def createBias(size,Name):\n",
    "        return tf.Variable(tf.constant(0.1,shape=size),\n",
    "                          name=Name)\n",
    "    \n",
    "    def conv2d_s1(x,W):\n",
    "        return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')\n",
    "    \n",
    "    def max_pool_3x3_s1(x):\n",
    "        return tf.nn.max_pool(x,ksize=[1,3,3,1],\n",
    "                             strides=[1,1,1,1],padding='SAME')\n",
    "    \n",
    "    \n",
    "    #Inception Module1\n",
    "    #\n",
    "    #follows input\n",
    "    W_conv1_1x1_1 = createWeight([1,1,1,map1],'W_conv1_1x1_1')\n",
    "    b_conv1_1x1_1 = createWeight([map1],'b_conv1_1x1_1')\n",
    "    \n",
    "    #follows input\n",
    "    W_conv1_1x1_2 = createWeight([1,1,1,reduce1x1],'W_conv1_1x1_2')\n",
    "    b_conv1_1x1_2 = createWeight([reduce1x1],'b_conv1_1x1_2')\n",
    "    \n",
    "    #follows input\n",
    "    W_conv1_1x1_3 = createWeight([1,1,1,reduce1x1],'W_conv1_1x1_3')\n",
    "    b_conv1_1x1_3 = createWeight([reduce1x1],'b_conv1_1x1_3')\n",
    "    \n",
    "    #follows 1x1_2\n",
    "    W_conv1_3x3 = createWeight([3,3,reduce1x1,map1],'W_conv1_3x3')\n",
    "    b_conv1_3x3 = createWeight([map1],'b_conv1_3x3')\n",
    "    \n",
    "    #follows 1x1_3\n",
    "    W_conv1_5x5 = createWeight([5,5,reduce1x1,map1],'W_conv1_5x5')\n",
    "    b_conv1_5x5 = createBias([map1],'b_conv1_5x5')\n",
    "    \n",
    "    #follows max pooling\n",
    "    W_conv1_1x1_4= createWeight([1,1,1,map1],'W_conv1_1x1_4')\n",
    "    b_conv1_1x1_4= createWeight([map1],'b_conv1_1x1_4')\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Inception Module2\n",
    "    #\n",
    "    #follows inception1\n",
    "    W_conv2_1x1_1 = createWeight([1,1,4*map1,map2],'W_conv2_1x1_1')\n",
    "    b_conv2_1x1_1 = createWeight([map2],'b_conv2_1x1_1')\n",
    "    \n",
    "    #follows inception1\n",
    "    W_conv2_1x1_2 = createWeight([1,1,4*map1,reduce1x1],'W_conv2_1x1_2')\n",
    "    b_conv2_1x1_2 = createWeight([reduce1x1],'b_conv2_1x1_2')\n",
    "    \n",
    "    #follows inception1\n",
    "    W_conv2_1x1_3 = createWeight([1,1,4*map1,reduce1x1],'W_conv2_1x1_3')\n",
    "    b_conv2_1x1_3 = createWeight([reduce1x1],'b_conv2_1x1_3')\n",
    "    \n",
    "    #follows 1x1_2\n",
    "    W_conv2_3x3 = createWeight([3,3,reduce1x1,map2],'W_conv2_3x3')\n",
    "    b_conv2_3x3 = createWeight([map2],'b_conv2_3x3')\n",
    "    \n",
    "    #follows 1x1_3\n",
    "    W_conv2_5x5 = createWeight([5,5,reduce1x1,map2],'W_conv2_5x5')\n",
    "    b_conv2_5x5 = createBias([map2],'b_conv2_5x5')\n",
    "    \n",
    "    #follows max pooling\n",
    "    W_conv2_1x1_4= createWeight([1,1,4*map1,map2],'W_conv2_1x1_4')\n",
    "    b_conv2_1x1_4= createWeight([map2],'b_conv2_1x1_4')\n",
    "    \n",
    "    \n",
    "\n",
    "    #Fully connected layers\n",
    "    #since padding is same, the feature map with there will be 4 28*28*map2\n",
    "    W_fc1 = createWeight([28*28*(4*map2),num_fc1],'W_fc1')\n",
    "    b_fc1 = createBias([num_fc1],'b_fc1')\n",
    "    \n",
    "    W_fc2 = createWeight([num_fc1,num_fc2],'W_fc2')\n",
    "    b_fc2 = createBias([num_fc2],'b_fc2')\n",
    "\n",
    "    def model(x,train=True):\n",
    "        #Inception Module 1\n",
    "        conv1_1x1_1 = conv2d_s1(x,W_conv1_1x1_1)+b_conv1_1x1_1\n",
    "        conv1_1x1_2 = tf.nn.relu(conv2d_s1(x,W_conv1_1x1_2)+b_conv1_1x1_2)\n",
    "        conv1_1x1_3 = tf.nn.relu(conv2d_s1(x,W_conv1_1x1_3)+b_conv1_1x1_3)\n",
    "        conv1_3x3 = conv2d_s1(conv1_1x1_2,W_conv1_3x3)+b_conv1_3x3\n",
    "        conv1_5x5 = conv2d_s1(conv1_1x1_3,W_conv1_5x5)+b_conv1_5x5\n",
    "        maxpool1 = max_pool_3x3_s1(x)\n",
    "        conv1_1x1_4 = conv2d_s1(maxpool1,W_conv1_1x1_4)+b_conv1_1x1_4\n",
    "        \n",
    "        #concatenate all the feature maps and hit them with a relu\n",
    "        inception1 = tf.nn.relu(tf.concat(3,[conv1_1x1_1,conv1_3x3,conv1_5x5,conv1_1x1_4]))\n",
    "\n",
    "        \n",
    "        #Inception Module 2\n",
    "        conv2_1x1_1 = conv2d_s1(inception1,W_conv2_1x1_1)+b_conv2_1x1_1\n",
    "        conv2_1x1_2 = tf.nn.relu(conv2d_s1(inception1,W_conv2_1x1_2)+b_conv2_1x1_2)\n",
    "        conv2_1x1_3 = tf.nn.relu(conv2d_s1(inception1,W_conv2_1x1_3)+b_conv2_1x1_3)\n",
    "        conv2_3x3 = conv2d_s1(conv2_1x1_2,W_conv2_3x3)+b_conv2_3x3\n",
    "        conv2_5x5 = conv2d_s1(conv2_1x1_3,W_conv2_5x5)+b_conv2_5x5\n",
    "        maxpool2 = max_pool_3x3_s1(inception1)\n",
    "        conv2_1x1_4 = conv2d_s1(maxpool2,W_conv2_1x1_4)+b_conv2_1x1_4\n",
    "        \n",
    "        #concatenate all the feature maps and hit them with a relu\n",
    "        inception2 = tf.nn.relu(tf.concat(3,[conv2_1x1_1,conv2_3x3,conv2_5x5,conv2_1x1_4]))\n",
    "\n",
    "        #flatten features for fully connected layer\n",
    "        inception2_flat = tf.reshape(inception2,[-1,28*28*4*map2])\n",
    "        \n",
    "        #Fully connected layers\n",
    "        if train:\n",
    "            h_fc1 =tf.nn.dropout(tf.nn.relu(tf.matmul(inception2_flat,W_fc1)+b_fc1),dropout)\n",
    "        else:\n",
    "            h_fc1 = tf.nn.relu(tf.matmul(inception2_flat,W_fc1)+b_fc1)\n",
    "\n",
    "        return tf.matmul(h_fc1,W_fc2)+b_fc2\n",
    "    \n",
    "    \n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(model(X),y_))\n",
    "    opt = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "    \n",
    "    predictions_val = tf.nn.softmax(model(tf_valX,train=False))\n",
    "    predictions_test = tf.nn.softmax(model(tf_testX,train=False))\n",
    "    \n",
    "    #initialize variable\n",
    "    init = tf.initialize_all_variables()\n",
    "    \n",
    "    #use to save variables so we can pick up later\n",
    "    saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "step: 0\n",
      "validation accuracy: 21.4\n",
      " \n",
      "step: 100\n",
      "validation accuracy: 91.6\n",
      " \n",
      "step: 200\n",
      "validation accuracy: 92.8\n",
      " \n",
      "step: 300\n",
      "validation accuracy: 93.4\n",
      " \n",
      "step: 400\n",
      "validation accuracy: 94.0\n",
      " \n",
      "step: 500\n",
      "validation accuracy: 91.2\n",
      " \n",
      "step: 600\n",
      "validation accuracy: 92.0\n",
      " \n",
      "step: 700\n",
      "validation accuracy: 90.2\n",
      " \n",
      "step: 800\n",
      "validation accuracy: 88.8\n",
      " \n",
      "step: 900\n",
      "validation accuracy: 89.0\n",
      " \n",
      "step: 1000\n",
      "validation accuracy: 90.4\n",
      " \n",
      "step: 1100\n",
      "validation accuracy: 92.0\n",
      " \n",
      "step: 1200\n",
      "validation accuracy: 90.4\n",
      " \n",
      "step: 1300\n",
      "validation accuracy: 93.0\n",
      " \n",
      "step: 1400\n",
      "validation accuracy: 91.6\n",
      " \n",
      "step: 1500\n",
      "validation accuracy: 93.0\n",
      " \n",
      "step: 1600\n",
      "validation accuracy: 94.2\n",
      " \n",
      "step: 1700\n",
      "validation accuracy: 94.8\n",
      " \n",
      "step: 1800\n",
      "validation accuracy: 93.4\n",
      " \n",
      "step: 1900\n",
      "validation accuracy: 92.6\n",
      " \n",
      "step: 2000\n",
      "validation accuracy: 92.8\n",
      " \n",
      "step: 2100\n",
      "validation accuracy: 93.2\n",
      " \n",
      "step: 2200\n",
      "validation accuracy: 93.2\n",
      " \n",
      "step: 2300\n",
      "validation accuracy: 93.4\n",
      " \n",
      "step: 2400\n",
      "validation accuracy: 92.8\n",
      " \n",
      "step: 2500\n",
      "validation accuracy: 92.2\n",
      " \n",
      "step: 2600\n",
      "validation accuracy: 94.6\n",
      " \n",
      "step: 2700\n",
      "validation accuracy: 94.6\n",
      " \n",
      "step: 2800\n",
      "validation accuracy: 95.2\n",
      " \n",
      "step: 2900\n",
      "validation accuracy: 93.4\n",
      " \n",
      "step: 3000\n",
      "validation accuracy: 94.0\n",
      " \n",
      "step: 3100\n",
      "validation accuracy: 94.6\n",
      " \n",
      "step: 3200\n",
      "validation accuracy: 94.4\n",
      " \n",
      "step: 3300\n",
      "validation accuracy: 94.0\n",
      " \n",
      "step: 3400\n",
      "validation accuracy: 94.6\n",
      " \n",
      "step: 3500\n",
      "validation accuracy: 94.6\n",
      " \n",
      "step: 3600\n",
      "validation accuracy: 96.2\n",
      " \n",
      "step: 3700\n",
      "validation accuracy: 95.6\n",
      " \n",
      "step: 3800\n",
      "validation accuracy: 95.0\n",
      " \n",
      "step: 3900\n",
      "validation accuracy: 93.8\n",
      " \n",
      "step: 4000\n",
      "validation accuracy: 95.4\n",
      " \n",
      "step: 4100\n",
      "validation accuracy: 95.2\n",
      " \n",
      "step: 4200\n",
      "validation accuracy: 95.4\n",
      " \n",
      "step: 4300\n",
      "validation accuracy: 95.6\n",
      " \n",
      "step: 4400\n",
      "validation accuracy: 94.6\n",
      " \n",
      "step: 4500\n",
      "validation accuracy: 96.2\n",
      " \n",
      "step: 4600\n",
      "validation accuracy: 95.2\n",
      " \n",
      "step: 4700\n",
      "validation accuracy: 96.6\n",
      " \n",
      "step: 4800\n",
      "validation accuracy: 94.8\n",
      " \n",
      "step: 4900\n",
      "validation accuracy: 92.6\n",
      " \n",
      "step: 5000\n",
      "validation accuracy: 95.0\n",
      " \n",
      "step: 5100\n",
      "validation accuracy: 95.0\n",
      " \n",
      "step: 5200\n",
      "validation accuracy: 95.0\n",
      " \n",
      "step: 5300\n",
      "validation accuracy: 95.2\n",
      " \n",
      "step: 5400\n",
      "validation accuracy: 95.8\n",
      " \n",
      "step: 5500\n",
      "validation accuracy: 96.0\n",
      " \n",
      "step: 5600\n",
      "validation accuracy: 95.6\n",
      " \n",
      "step: 5700\n",
      "validation accuracy: 96.4\n",
      " \n",
      "step: 5800\n",
      "validation accuracy: 96.4\n",
      " \n",
      "step: 5900\n",
      "validation accuracy: 96.8\n",
      " \n",
      "step: 6000\n",
      "validation accuracy: 96.6\n",
      " \n",
      "step: 6100\n",
      "validation accuracy: 96.6\n",
      " \n",
      "step: 6200\n",
      "validation accuracy: 95.2\n",
      " \n",
      "step: 6300\n",
      "validation accuracy: 97.2\n",
      " \n",
      "step: 6400\n",
      "validation accuracy: 95.8\n",
      " \n",
      "step: 6500\n",
      "validation accuracy: 96.6\n",
      " \n",
      "step: 6600\n",
      "validation accuracy: 96.0\n",
      " \n",
      "step: 6700\n",
      "validation accuracy: 96.6\n",
      " \n",
      "step: 6800\n",
      "validation accuracy: 97.0\n",
      " \n",
      "step: 6900\n",
      "validation accuracy: 97.0\n",
      " \n",
      "step: 7000\n",
      "validation accuracy: 96.2\n",
      " \n",
      "step: 7100\n",
      "validation accuracy: 97.6\n",
      " \n",
      "step: 7200\n",
      "validation accuracy: 96.8\n",
      " \n",
      "step: 7300\n",
      "validation accuracy: 97.8\n",
      " \n",
      "step: 7400\n",
      "validation accuracy: 96.6\n",
      " \n",
      "step: 7500\n",
      "validation accuracy: 96.8\n",
      " \n",
      "step: 7600\n",
      "validation accuracy: 96.8\n",
      " \n",
      "step: 7700\n",
      "validation accuracy: 97.4\n",
      " \n",
      "step: 7800\n",
      "validation accuracy: 97.2\n",
      " \n",
      "step: 7900\n",
      "validation accuracy: 97.4\n",
      " \n",
      "step: 8000\n",
      "validation accuracy: 97.8\n",
      " \n",
      "step: 8100\n",
      "validation accuracy: 97.8\n",
      " \n",
      "step: 8200\n",
      "validation accuracy: 98.2\n",
      " \n",
      "step: 8300\n",
      "validation accuracy: 97.2\n",
      " \n",
      "step: 8400\n",
      "validation accuracy: 97.0\n",
      " \n",
      "step: 8500\n",
      "validation accuracy: 97.6\n",
      " \n",
      "step: 8600\n",
      "validation accuracy: 97.4\n",
      " \n",
      "step: 8700\n",
      "validation accuracy: 97.4\n",
      " \n",
      "step: 8800\n",
      "validation accuracy: 97.4\n",
      " \n",
      "step: 8900\n",
      "validation accuracy: 97.6\n",
      " \n",
      "step: 9000\n",
      "validation accuracy: 97.2\n",
      " \n",
      "step: 9100\n",
      "validation accuracy: 97.8\n",
      " \n",
      "step: 9200\n",
      "validation accuracy: 97.6\n",
      " \n",
      "step: 9300\n",
      "validation accuracy: 97.0\n",
      " \n",
      "step: 9400\n",
      "validation accuracy: 97.4\n",
      " \n",
      "step: 9500\n",
      "validation accuracy: 97.6\n",
      " \n",
      "step: 9600\n",
      "validation accuracy: 97.0\n",
      " \n",
      "step: 9700\n",
      "validation accuracy: 97.0\n",
      " \n",
      "step: 9800\n",
      "validation accuracy: 97.4\n",
      " \n",
      "step: 9900\n",
      "validation accuracy: 97.8\n",
      " \n",
      "step: 10000\n",
      "validation accuracy: 98.0\n",
      " \n",
      "step: 10100\n",
      "validation accuracy: 97.8\n",
      " \n",
      "step: 10200\n",
      "validation accuracy: 97.6\n",
      " \n",
      "step: 10300\n",
      "validation accuracy: 98.0\n",
      " \n",
      "step: 10400\n",
      "validation accuracy: 97.8\n",
      " \n",
      "step: 10500\n",
      "validation accuracy: 97.8\n",
      " \n",
      "step: 10600\n",
      "validation accuracy: 98.2\n",
      " \n",
      "step: 10700\n",
      "validation accuracy: 97.8\n",
      " \n",
      "step: 10800\n",
      "validation accuracy: 98.0\n",
      " \n",
      "step: 10900\n",
      "validation accuracy: 98.2\n",
      " \n",
      "step: 11000\n",
      "validation accuracy: 97.8\n",
      " \n",
      "step: 11100\n",
      "validation accuracy: 98.4\n",
      " \n",
      "step: 11200\n",
      "validation accuracy: 97.2\n",
      " \n",
      "step: 11300\n",
      "validation accuracy: 98.0\n",
      " \n",
      "step: 11400\n",
      "validation accuracy: 97.8\n",
      " \n",
      "step: 11500\n",
      "validation accuracy: 97.0\n",
      " \n",
      "step: 11600\n",
      "validation accuracy: 98.4\n",
      " \n",
      "step: 11700\n",
      "validation accuracy: 98.0\n",
      " \n",
      "step: 11800\n",
      "validation accuracy: 98.0\n",
      " \n",
      "step: 11900\n",
      "validation accuracy: 97.6\n",
      " \n",
      "step: 12000\n",
      "validation accuracy: 97.4\n",
      " \n",
      "step: 12100\n",
      "validation accuracy: 98.4\n",
      " \n",
      "step: 12200\n",
      "validation accuracy: 98.2\n",
      " \n",
      "step: 12300\n",
      "validation accuracy: 97.8\n",
      " \n",
      "step: 12400\n",
      "validation accuracy: 97.8\n",
      " \n",
      "step: 12500\n",
      "validation accuracy: 97.8\n",
      " \n",
      "step: 12600\n",
      "validation accuracy: 98.2\n",
      " \n",
      "step: 12700\n",
      "validation accuracy: 98.2\n",
      " \n",
      "step: 12800\n",
      "validation accuracy: 98.2\n",
      " \n",
      "step: 12900\n",
      "validation accuracy: 98.2\n",
      " \n",
      "step: 13000\n",
      "validation accuracy: 98.2\n",
      " \n",
      "step: 13100\n",
      "validation accuracy: 98.6\n",
      " \n",
      "step: 13200\n",
      "validation accuracy: 98.4\n",
      " \n",
      "step: 13300\n",
      "validation accuracy: 98.0\n",
      " \n",
      "step: 13400\n",
      "validation accuracy: 97.8\n",
      " \n",
      "step: 13500\n",
      "validation accuracy: 98.4\n",
      " \n",
      "step: 13600\n",
      "validation accuracy: 98.2\n",
      " \n",
      "step: 13700\n",
      "validation accuracy: 98.0\n",
      " \n",
      "step: 13800\n",
      "validation accuracy: 98.0\n",
      " \n",
      "step: 13900\n",
      "validation accuracy: 98.2\n",
      " \n",
      "step: 14000\n",
      "validation accuracy: 98.2\n",
      " \n",
      "step: 14100\n",
      "validation accuracy: 97.8\n",
      " \n",
      "step: 14200\n",
      "validation accuracy: 98.0\n",
      " \n",
      "step: 14300\n",
      "validation accuracy: 98.2\n",
      " \n",
      "step: 14400\n",
      "validation accuracy: 98.0\n",
      " \n",
      "step: 14500\n",
      "validation accuracy: 98.0\n",
      " \n",
      "step: 14600\n",
      "validation accuracy: 97.8\n",
      " \n",
      "step: 14700\n",
      "validation accuracy: 97.6\n",
      " \n",
      "step: 14800\n",
      "validation accuracy: 98.4\n",
      " \n",
      "step: 14900\n",
      "validation accuracy: 98.4\n",
      " \n",
      "step: 15000\n",
      "validation accuracy: 98.2\n",
      " \n",
      "step: 15100\n",
      "validation accuracy: 98.4\n",
      " \n",
      "step: 15200\n",
      "validation accuracy: 97.6\n",
      " \n",
      "step: 15300\n",
      "validation accuracy: 97.2\n",
      " \n",
      "step: 15400\n",
      "validation accuracy: 98.0\n",
      " \n",
      "step: 15500\n",
      "validation accuracy: 98.0\n",
      " \n",
      "step: 15600\n",
      "validation accuracy: 97.8\n",
      " \n",
      "step: 15700\n",
      "validation accuracy: 98.6\n",
      " \n",
      "step: 15800\n",
      "validation accuracy: 98.4\n",
      " \n",
      "step: 15900\n",
      "validation accuracy: 97.8\n",
      " \n",
      "step: 16000\n",
      "validation accuracy: 97.8\n",
      " \n",
      "step: 16100\n",
      "validation accuracy: 98.4\n",
      " \n",
      "step: 16200\n",
      "validation accuracy: 98.6\n",
      " \n",
      "step: 16300\n",
      "validation accuracy: 98.2\n",
      " \n",
      "step: 16400\n",
      "validation accuracy: 98.4\n",
      " \n",
      "step: 16500\n",
      "validation accuracy: 97.8\n",
      " \n",
      "step: 16600\n",
      "validation accuracy: 98.2\n",
      " \n",
      "step: 16700\n",
      "validation accuracy: 98.2\n",
      " \n",
      "step: 16800\n",
      "validation accuracy: 98.2\n",
      " \n",
      "step: 16900\n",
      "validation accuracy: 98.2\n",
      " \n",
      "step: 17000\n",
      "validation accuracy: 98.2\n",
      " \n",
      "step: 17100\n",
      "validation accuracy: 97.8\n",
      " \n",
      "step: 17200\n",
      "validation accuracy: 98.6\n",
      " \n",
      "step: 17300\n",
      "validation accuracy: 98.2\n",
      " \n",
      "step: 17400\n",
      "validation accuracy: 98.6\n",
      " \n",
      "step: 17500\n",
      "validation accuracy: 98.0\n",
      " \n",
      "step: 17600\n",
      "validation accuracy: 97.6\n",
      " \n",
      "step: 17700\n",
      "validation accuracy: 98.2\n",
      " \n",
      "step: 17800\n",
      "validation accuracy: 98.6\n",
      " \n",
      "step: 17900\n",
      "validation accuracy: 98.0\n",
      " \n",
      "step: 18000\n",
      "validation accuracy: 97.6\n",
      " \n",
      "step: 18100\n",
      "validation accuracy: 98.2\n",
      " \n",
      "step: 18200\n",
      "validation accuracy: 98.4\n",
      " \n",
      "step: 18300\n",
      "validation accuracy: 98.2\n",
      " \n",
      "step: 18400\n",
      "validation accuracy: 98.0\n",
      " \n",
      "step: 18500\n",
      "validation accuracy: 98.0\n",
      " \n",
      "step: 18600\n",
      "validation accuracy: 98.4\n",
      " \n",
      "step: 18700\n",
      "validation accuracy: 98.8\n",
      " \n",
      "step: 18800\n",
      "validation accuracy: 98.4\n",
      " \n",
      "step: 18900\n",
      "validation accuracy: 98.6\n",
      " \n",
      "step: 19000\n",
      "validation accuracy: 98.6\n",
      " \n",
      "step: 19100\n",
      "validation accuracy: 98.4\n",
      " \n",
      "step: 19200\n",
      "validation accuracy: 98.6\n",
      " \n",
      "step: 19300\n",
      "validation accuracy: 98.6\n",
      " \n",
      "step: 19400\n",
      "validation accuracy: 98.6\n",
      " \n",
      "step: 19500\n",
      "validation accuracy: 98.6\n",
      " \n",
      "step: 19600\n",
      "validation accuracy: 98.6\n",
      " \n",
      "step: 19700\n",
      "validation accuracy: 98.4\n",
      " \n",
      "step: 19800\n",
      "validation accuracy: 98.6\n",
      " \n",
      "step: 19900\n",
      "validation accuracy: 98.4\n",
      " \n",
      "test accuracy: 98.6\n",
      "Model saved.\n"
     ]
    }
   ],
   "source": [
    "num_steps = 20000\n",
    "sess = tf.Session(graph=graph)\n",
    "\n",
    "#initialize variables\n",
    "sess.run(init)\n",
    "print(\"Model initialized.\")\n",
    "\n",
    "#set use_previous=1 to use file_path model\n",
    "#set use_previous=0 to start model from scratch\n",
    "use_previous = 0\n",
    "\n",
    "#use the previous model or don't and initialize variables\n",
    "if use_previous:\n",
    "    saver.restore(sess,file_path)\n",
    "    print(\"Model restored.\")\n",
    "\n",
    "#training\n",
    "for s in range(num_steps):\n",
    "    offset = (s*batch_size) % (len(trainX)-batch_size)\n",
    "    batch_x,batch_y = trainX[offset:(offset+batch_size),:],train_lb[offset:(offset+batch_size),:]\n",
    "    feed_dict={X : batch_x, y_ : batch_y}\n",
    "    _,loss_value = sess.run([opt,loss],feed_dict=feed_dict)\n",
    "    if s%100 == 0:\n",
    "        feed_dict = {tf_valX : valX}\n",
    "        preds=sess.run(predictions_val,feed_dict=feed_dict)\n",
    "        \n",
    "        print \"step: \"+str(s)\n",
    "        print \"validation accuracy: \"+str(accuracy(val_lb,preds))\n",
    "        print \" \"\n",
    "        \n",
    "    #get test accuracy and save model\n",
    "    if s == (num_steps-1):\n",
    "        #create an array to store the outputs for the test\n",
    "        result = np.array([]).reshape(0,10)\n",
    "\n",
    "        #use the batches class\n",
    "        batch_testX=test_batchs(testX)\n",
    "\n",
    "        for i in range(len(testX)/test_batch_size):\n",
    "            feed_dict = {tf_testX : batch_testX.nextBatch(test_batch_size)}\n",
    "            preds=sess.run(predictions_test, feed_dict=feed_dict)\n",
    "            result=np.concatenate((result,preds),axis=0)\n",
    "        \n",
    "        print \"test accuracy: \"+str(accuracy(test_lb,result))\n",
    "        \n",
    "        save_path = saver.save(sess,file_path)\n",
    "        print(\"Model saved.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
